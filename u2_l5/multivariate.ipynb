{
 "metadata": {
  "name": "",
  "signature": "sha256:ebccaf35a7f409ae482e7aa04d6a1f5429900ae8f48943fb8a08bee270c33087"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Multivariate: https://courses.thinkful.com/data-001v2/project/2.5.2\n",
      "\n",
      "1. Load the Lending Club Statistics.\n",
      "\n",
      "2. Use income (annual_inc) to model interest rates (int_rate).\n",
      "\n",
      "3. Add home ownership (home_ownership) to the model.\n",
      "\n",
      "4. Does that affect the significance of the coefficients in the original model?\n",
      "\n",
      "5. Try to add the interaction of home ownership and incomes as a term. How does this impact the new model?\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Load the Lending Club Statistics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Data is a local copy of https://resources.lendingclub.com/LoanStats3d.csv.zip\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statsmodels.api as sm\n",
      "\n",
      "data = pd.read_csv('LoanStats3d.csv', skiprows=[0], low_memory=False)\n",
      "\n",
      "data['home_ownership'] = data['home_ownership'].map(lambda x: 1 if x=='OWN' else 0)\n",
      "\n",
      "data.dropna(subset=('annual_inc', 'int_rate', 'home_ownership'), inplace=True)\n",
      "\n",
      "data['annual_inc'].astype(float)\n",
      "data['int_rate'] = [float(str(e).strip('%')) for e in data['int_rate']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Use income (annual_inc) to model interest rates (int_rate)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = data[['annual_inc']]\n",
      "y = data['int_rate']\n",
      "\n",
      "X = sm.add_constant(X)\n",
      "est = sm.OLS(y, X).fit()\n",
      "\n",
      "est.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>        <td>int_rate</td>     <th>  R-squared:         </th>  <td>   0.009</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.009</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2726.</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Thu, 28 Jan 2016</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>18:02:55</td>     <th>  Log-Likelihood:    </th> <td>-8.3964e+05</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>290591</td>      <th>  AIC:               </th>  <td>1.679e+06</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>290589</td>      <th>  BIC:               </th>  <td>1.679e+06</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>const</th>      <td>   13.2418</td> <td>    0.012</td> <td> 1078.643</td> <td> 0.000</td> <td>   13.218    13.266</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>annual_inc</th> <td>-6.336e-06</td> <td> 1.21e-07</td> <td>  -52.214</td> <td> 0.000</td> <td>-6.57e-06  -6.1e-06</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td>15431.694</td> <th>  Durbin-Watson:     </th> <td>   1.990</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>18215.084</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>           <td> 0.577</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>       <td> 3.417</td>   <th>  Cond. No.          </th> <td>1.54e+05</td> \n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:               int_rate   R-squared:                       0.009\n",
        "Model:                            OLS   Adj. R-squared:                  0.009\n",
        "Method:                 Least Squares   F-statistic:                     2726.\n",
        "Date:                Thu, 28 Jan 2016   Prob (F-statistic):               0.00\n",
        "Time:                        18:02:55   Log-Likelihood:            -8.3964e+05\n",
        "No. Observations:              290591   AIC:                         1.679e+06\n",
        "Df Residuals:                  290589   BIC:                         1.679e+06\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const         13.2418      0.012   1078.643      0.000        13.218    13.266\n",
        "annual_inc -6.336e-06   1.21e-07    -52.214      0.000     -6.57e-06  -6.1e-06\n",
        "==============================================================================\n",
        "Omnibus:                    15431.694   Durbin-Watson:                   1.990\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18215.084\n",
        "Skew:                           0.577   Prob(JB):                         0.00\n",
        "Kurtosis:                       3.417   Cond. No.                     1.54e+05\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "[2] The condition number is large, 1.54e+05. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems.\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 3. Add home ownership (home_ownership) to the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = data[['annual_inc', 'home_ownership']]\n",
      "y = data['int_rate']\n",
      "\n",
      "X = sm.add_constant(X)\n",
      "est = sm.OLS(y, X).fit()\n",
      "\n",
      "est.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-44-11f6b2aeb41f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/statsmodels/regression/linear_model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    689\u001b[0m                  **kwargs):\n\u001b[0;32m    690\u001b[0m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[1;32m--> 691\u001b[1;33m                                   hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[0;32m    692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/statsmodels/regression/linear_model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[1;32m--> 586\u001b[1;33m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/statsmodels/regression/linear_model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \"\"\"\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pinv_wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wendog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/statsmodels/base/model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/statsmodels/base/model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[1;32m---> 60\u001b[1;33m                                       **kwargs)\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/statsmodels/base/model.pyc\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/statsmodels/base/data.pyc\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[1;32m--> 566\u001b[1;33m                  **kwargs)\n\u001b[0m",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/statsmodels/base/data.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_endog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_exog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# this has side-effects, attaches k_constant and const_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/site-packages/statsmodels/base/data.pyc\u001b[0m in \u001b[0;36m_convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n\u001b[0m\u001b[0;32m    429\u001b[0m                              \"Check input data with np.asarray(data).\")\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPandasData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 4. Does that affect the significance of the coefficients in the original model?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 5. Try to add the interaction of home ownership and incomes as a term. How does this impact the new model?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = data[['annual_inc']]\n",
      "y = data['home_ownership']\n",
      "\n",
      "X = sm.add_constant(X)\n",
      "est = sm.Logit(y, X).fit()\n",
      "\n",
      "est.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimization terminated successfully.\n",
        "         Current function value: 0.339570\n",
        "         Iterations 6\n"
       ]
      },
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>Logit Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>  <td>home_ownership</td>  <th>  No. Observations:  </th>  <td>290591</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>290589</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>          <td>Thu, 28 Jan 2016</td> <th>  Pseudo R-squ.:     </th> <td>0.001623</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>              <td>18:06:49</td>     <th>  Log-Likelihood:    </th> <td> -98676.</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -98836.</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>9.884e-72</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>const</th>      <td>   -1.9462</td> <td>    0.012</td> <td> -164.631</td> <td> 0.000</td> <td>   -1.969    -1.923</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>annual_inc</th> <td>-2.385e-06</td> <td> 1.42e-07</td> <td>  -16.809</td> <td> 0.000</td> <td>-2.66e-06 -2.11e-06</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                           Logit Regression Results                           \n",
        "==============================================================================\n",
        "Dep. Variable:         home_ownership   No. Observations:               290591\n",
        "Model:                          Logit   Df Residuals:                   290589\n",
        "Method:                           MLE   Df Model:                            1\n",
        "Date:                Thu, 28 Jan 2016   Pseudo R-squ.:                0.001623\n",
        "Time:                        18:06:49   Log-Likelihood:                -98676.\n",
        "converged:                       True   LL-Null:                       -98836.\n",
        "                                        LLR p-value:                 9.884e-72\n",
        "==============================================================================\n",
        "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const         -1.9462      0.012   -164.631      0.000        -1.969    -1.923\n",
        "annual_inc -2.385e-06   1.42e-07    -16.809      0.000     -2.66e-06 -2.11e-06\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}